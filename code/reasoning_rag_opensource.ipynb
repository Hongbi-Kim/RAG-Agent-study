{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deepseek+Exaone+Docling으로 오픈소스 Reasoning RAG 구축하기\n",
    "- https://youtu.be/4j6J-9hxfhk?si=oWnmZatfye60k107\n",
    "\n",
    "- Docling: Entitiy를 모두 파싱하고, 적절한 처리 파이프라인으로 따르도록 만들고 쉽게 LLM이 이해할 수 있도록 마크다운으로 변환하는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langgraph langchain-docling langchain-qdrant langchain-text-splitters langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "reasoning_llm = ChatOllama(\n",
    "    model=\"deepseek-r1:7b\", # 추론 모델\n",
    "    stop=[\"</think>\"]\n",
    ")\n",
    "\n",
    "answer_llm = ChatOllama(\n",
    "    model = \"exaone3.5\", # 한국 모델\n",
    "    temperature = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, TypedDict, Literal\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# RAG 상태 정의\n",
    "class RAGState(TypedDict):\n",
    "    \"\"\"RAG 시스템의 상태를 정의합니다.\"\"\"\n",
    "    query: str\n",
    "    thinking: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "    messages: Annotated[List, add_messages]\n",
    "    mode: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "\n",
    "FILE_PATH = \"https://arxiv.org/pdf/2408.09869\"\n",
    "\n",
    "# 시간 오래 걸림\n",
    "# 내부적으로 레이아웃을 파싱하고, LLM이 이해하기 쉽게 Rule-Based로 수행.\n",
    "loader = DoclingLoader(\n",
    "    file_path = FILE_PATH,\n",
    "    export_type = ExportType.MARKDOWN\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- d.page_content='Version 1.0  \\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar  \\nAI4K Group, IBM Research R¨ uschlikon, Switzerland'\n",
      "- d.page_content='This technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
      "- d.page_content='Converting PDF documents back into a machine-processable format has been a major challenge for decades due to their huge variability in formats, weak standardization and printing-optimized characteristic, which discards most structural features and metadata. With the advent of LLMs and popular application patterns such as retrieval-augmented generation (RAG), leveraging the rich content embedded in PDFs has become ever more relevant. In the past decade, several powerful document understanding solutions have emerged on the market, most of which are commercial software, cloud offerings [3] and most recently, multi-modal vision-language models. As of today, only a handful of open-source tools cover PDF conversion, leaving a significant feature and quality gap to proprietary solutions.  \\nWith Docling , we open-source a very capable and efficient document conversion tool which builds on the powerful, specialized AI models and datasets for layout analysis and table structure recognition we developed and presented in the recent past [12, 13, 9]. Docling is designed as a simple, self-contained python library with permissive license, running entirely locally on commodity hardware. Its code architecture allows for easy extensibility and addition of new features and models.  \\nHere is what Docling delivers today:  \\n- Converts PDF documents to JSON or Markdown format, stable and lightning fast\\n- Understands detailed page layout, reading order, locates figures and recovers table structures\\n- Extracts metadata from the document, such as title, authors, references and language\\n- Optionally applies OCR, e.g. for scanned PDFs\\n- Can be configured to be optimal for batch-mode (i.e high throughput, low time-to-solution) or interactive mode (compromise on efficiency, low time-to-solution)\\n- Can leverage different accelerators (GPU, MPS, etc).'\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=[\n",
    "        (\"#\", \"Header_1\"),\n",
    "        (\"##\", \"Header_2\"),\n",
    "        (\"###\", \"Header_3\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
    "\n",
    "for d in splits[:3]:\n",
    "    print(f\"- {d.page_content=}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In this section, we establish some reference numbers for the processing speed of Docling and the resource budget it requires. All tests in this section are run with default options on our standard test set distributed with Docling, which consists of three papers from arXiv and two IBM Redbooks, with a total of 225 pages. Measurements were taken using both available PDF backends on two different hardware systems: one MacBook Pro M3 Max, and one bare-metal server running Ubuntu 20.04 LTS on an Intel Xeon E5-2690 CPU. For reproducibility, we fixed the thread budget (through setting OMP NUM THREADS environment variable ) once to 4 (Docling default) and once to 16 (equal to full core count on the test hardware). All results are shown in Table 1.  \n",
       "If you need to run Docling in very low-resource environments, please consider configuring the pypdfium backend. While it is faster and more memory efficient than the default docling-parse backend, it will come at the expense of worse quality results, especially in table structure recovery.  \n",
       "Establishing GPU acceleration support for the AI models is currently work-in-progress and largely untested, but may work implicitly when CUDA is available and discovered by the onnxruntime and  \n",
       "torch runtimes backing the Docling pipeline. We will deliver updates on this topic at in a future version of this report.  \n",
       "Table 1: Runtime characteristics of Docling with the standard model pipeline and settings, on our test dataset of 225 pages, on two different systems. OCR is disabled. We show the time-to-solution (TTS), computed throughput in pages per second, and the peak memory used (resident set size) for both the Docling-native PDF backend and for the pypdfium backend, using 4 and 16 threads.  \n",
       "| CPU                              | Thread budget   | native backend   | native backend   | native backend   | pypdfium backend   | pypdfium backend   | pypdfium backend   |\n",
       "|----------------------------------|-----------------|------------------|------------------|------------------|--------------------|--------------------|--------------------|\n",
       "|                                  |                 | TTS              | Pages/s          | Mem              | TTS                | Pages/s            | Mem                |\n",
       "| Apple M3 Max                     | 4               | 177 s 167 s      | 1.27 1.34        | 6.20 GB          | 103 s 92 s         | 2.18 2.45          | 2.56 GB            |\n",
       "| (16 cores) Intel(R) Xeon E5-2690 | 16 4 16         | 375 s 244 s      | 0.60 0.92        | 6.16 GB          | 239 s 143 s        | 0.94 1.57          | 2.42 GB            |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(splits[12].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model = \"bge-m3:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_qdrant import RetrievalMode\n",
    "\n",
    "vector_store = QdrantVectorStore.from_documents(\n",
    "    documents=splits,\n",
    "    embedding = embeddings,\n",
    "    location = \":memory:\",\n",
    "    collection_name = \"rag_collection\",\n",
    "    retrieval_mode = RetrievalMode.DENSE\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs = {\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "model = HuggingFaceCrossEncoder(model_name = \"BAAI/bge-reranker-base\")\n",
    "compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContextualCompressionRetriever(base_compressor=CrossEncoderReranker(model=HuggingFaceCrossEncoder(client=CrossEncoder(\n",
       "  (model): XLMRobertaForSequenceClassification(\n",
       "    (roberta): XLMRobertaModel(\n",
       "      (embeddings): XLMRobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): XLMRobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x XLMRobertaLayer(\n",
       "            (attention): XLMRobertaAttention(\n",
       "              (self): XLMRobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): XLMRobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): XLMRobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): XLMRobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (classifier): XLMRobertaClassificationHead(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (activation_fn): Sigmoid()\n",
       "), model_name='BAAI/bge-reranker-base', model_kwargs={}), top_n=5), base_retriever=VectorStoreRetriever(tags=['QdrantVectorStore', 'OllamaEmbeddings'], vectorstore=<langchain_qdrant.qdrant.QdrantVectorStore object at 0x348613df0>, search_kwargs={'k': 10}))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "\n",
    "# 1. 질문 분류 함수 - 중요: 여기서는 상태를 업데이트하는 노드 함수\n",
    "def classify_node(state: RAGState):\n",
    "    \"\"\"질문을 분류하여 처리 모드를 결정합니다.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    # 모드를 상태에 저장\n",
    "    if \"Docling\" in query:\n",
    "        print(\"===검색 시작===\")\n",
    "        return {\"mode\": \"retrieve\"}\n",
    "    else:\n",
    "        print(\"===생성 시작===\")\n",
    "        return {\"mode\": \"generate\"}\n",
    "    \n",
    "# 2. 검색 노드 - 검색 후 상태 업데이트\n",
    "def retrieve_node(state: RAGState):\n",
    "    \"\"\"문서를 검색하고 상태를 업데이트합니다.\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    documents = compression_retriever.invoke(query)\n",
    "    print(f\"===검색 완료: {len(documents)}개의 문서 검색됨===\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "# 3. 추론 노드 - 상태 업데이트 \n",
    "def think_node(state: RAGState):\n",
    "    \"\"\"추론 모델을 사용하여 생각을 생성합니다.\"\"\"   \n",
    "    query = state[\"query\"]\n",
    "    documents = state[\"documents\"]\n",
    "    thinking = reasoning_llm.invoke(\n",
    "        f\"<think> {query} </think> {documents}\"\n",
    "    )\n",
    "    # AIMessage에서 content만 추출\n",
    "    thinking_content = thinking.content\n",
    "    print(f\"===추론 완료: {thinking_content}===\")\n",
    "    return {\"thinking\": thinking_content}\n",
    "\n",
    "# 4. 답변 생성 노드 - 상태 업데이트\n",
    "def answer_node(state: RAGState):\n",
    "    \"\"\"답변 모델을 사용하여 최종 답변을 생성합니다.\"\"\"\n",
    "    thinking = state[\"thinking\"]\n",
    "    # thinking의 content 부분만 추출하여 프롬프트 구성\n",
    "    prompt = f\"{thinking}\"\n",
    "    # 메시지 생성 및 모델 호출\n",
    "    message = HumanMessage(content=prompt)\n",
    "    response = answer_llm.invoke([message])\n",
    "    answer = response.content\n",
    "    print(f\"===답변 생성 완료: {answer}===\")\n",
    "    return {\"answer\": answer}  # 반드시 answer를 딕셔너리 형태로 반환\n",
    "\n",
    "# 5. 워크플로우 생성\n",
    "workflow = StateGraph(RAGState)\n",
    "\n",
    "# 시작 노드에서 분류 노드로\n",
    "workflow.add_node(\"classify\", classify_node)\n",
    "# 분류 노드 이후 조건부 라우팅\n",
    "workflow.add_conditional_edges(\n",
    "    \"classify\",\n",
    "    lambda x: x[\"mode\"],\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"generate\": \"answer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 검색 노드에서 추론 노드로\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_edge(\"retrieve\", \"think\")\n",
    "\n",
    "# 추론 노드에서 답변 노드로\n",
    "workflow.add_node(\"think\", think_node)\n",
    "workflow.add_edge(\"think\", \"answer\")\n",
    "\n",
    "# 답변 노드 추가 및 종료\n",
    "workflow.add_node(\"answer\", answer_node)\n",
    "workflow.add_edge(\"answer\", END)\n",
    "\n",
    "# 시작점 설정\n",
    "workflow.set_entry_point(\"classify\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = workflow.compile()\n",
    "\n",
    "# RAG 시스템 실행 함수\n",
    "def run_rag_system(query: str) -> str:\n",
    "    \"\"\"RAG 시스템을 실행하여 질문에 대한 답변을 생성합니다.\"\"\"\n",
    "    result = graph.invoke({\n",
    "        \"query\": query,\n",
    "        \"documents\": [],\n",
    "        \"thinking\": \"\",\n",
    "        \"answer\": \"\",\n",
    "        \"messages\": [],\n",
    "        \"mode\": \"\"\n",
    "    })\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===검색 시작===\n",
      "===검색 완료: 5개의 문서 검색됨===\n",
      "===추론 완료: <think>\n",
      "Alright, I need to explain Docling based on the provided information. Let me start by understanding what each document says.\n",
      "\n",
      "Docling is an open-source PDF converter. The first document explains its extensibility with a model pipeline for customization. It mentions implementing a linear processing pipeline that works page-by-page. The introduction highlights its challenges in converting PDFs due to their variability and the gap between open-source tools and commercial ones.\n",
      "\n",
      "Looking at the other documents, they talk about versioning (1, 2, 3, 4) but maybe it's just part of how the information is structured. The key features are:\n",
      "- Converts PDFs to JSON or Markdown quickly.\n",
      "- Understands page layout, reading order, figures, and table structures.\n",
      "- Extracts metadata like title, authors, etc.\n",
      "- Supports OCR for scanned PDFs.\n",
      "- Works in batch or interactive mode.\n",
      "- Can use GPUs for acceleration.\n",
      "\n",
      "The abstract summarizes it as a self-contained MIT tool with state-of-the-art AI models. The future work includes adding more models like figures and equations, improving GPU support, and testing.\n",
      "\n",
      "Putting this together, I should explain that Docling is designed to be simple, efficient, extensible, and covers various features for PDF conversion.\n",
      "===\n",
      "===답변 생성 완료: Certainly! Here’s a concise explanation of Docling based on the provided information:\n",
      "\n",
      "**Docling** is an open-source PDF converter designed to address the complexities and variability inherent in PDF documents through advanced AI capabilities. Here are its key features and strengths:\n",
      "\n",
      "1. **Efficiency and Speed**: Docling quickly converts PDFs into structured formats like JSON or Markdown, making it highly efficient for both batch and interactive use cases.\n",
      "\n",
      "2. **Advanced Parsing**: It excels at understanding complex PDF structures, including:\n",
      "   - **Page Layout**: Accurate interpretation of text placement and layout.\n",
      "   - **Reading Order**: Proper sequencing of content for readability.\n",
      "   - **Figures and Tables**: Extraction and preservation of visual elements and tabular data.\n",
      "   - **Metadata**: Extraction of essential metadata such as titles, authors, and other document properties.\n",
      "\n",
      "3. **Versatility**: Docling supports OCR (Optical Character Recognition) for scanned PDFs, ensuring that even non-text content can be effectively processed.\n",
      "\n",
      "4. **Flexibility**: \n",
      "   - **Extensibility**: Built with a modular pipeline architecture, allowing for customization and integration with various AI models.\n",
      "   - **Mode Support**: Operates seamlessly in both batch processing and interactive modes, catering to diverse user needs.\n",
      "   - **Acceleration**: Leverages GPU support for faster processing, enhancing performance significantly.\n",
      "\n",
      "5. **Open-Source and Community-Driven**: As an open-source tool, Docling benefits from community contributions and continuous improvement, aiming to bridge the gap between open-source and commercial PDF conversion tools.\n",
      "\n",
      "6. **Future Enhancements**: Ongoing development focuses on expanding model capabilities (e.g., better figure and equation extraction), enhancing GPU utilization, and thorough testing to ensure robustness and reliability.\n",
      "\n",
      "In summary, Docling stands out as a powerful, flexible, and community-supported tool designed to simplify and enhance PDF document conversion with state-of-the-art AI features.===\n",
      "최종 답변: Certainly! Here’s a concise explanation of Docling based on the provided information:\n",
      "\n",
      "**Docling** is an open-source PDF converter designed to address the complexities and variability inherent in PDF documents through advanced AI capabilities. Here are its key features and strengths:\n",
      "\n",
      "1. **Efficiency and Speed**: Docling quickly converts PDFs into structured formats like JSON or Markdown, making it highly efficient for both batch and interactive use cases.\n",
      "\n",
      "2. **Advanced Parsing**: It excels at understanding complex PDF structures, including:\n",
      "   - **Page Layout**: Accurate interpretation of text placement and layout.\n",
      "   - **Reading Order**: Proper sequencing of content for readability.\n",
      "   - **Figures and Tables**: Extraction and preservation of visual elements and tabular data.\n",
      "   - **Metadata**: Extraction of essential metadata such as titles, authors, and other document properties.\n",
      "\n",
      "3. **Versatility**: Docling supports OCR (Optical Character Recognition) for scanned PDFs, ensuring that even non-text content can be effectively processed.\n",
      "\n",
      "4. **Flexibility**: \n",
      "   - **Extensibility**: Built with a modular pipeline architecture, allowing for customization and integration with various AI models.\n",
      "   - **Mode Support**: Operates seamlessly in both batch processing and interactive modes, catering to diverse user needs.\n",
      "   - **Acceleration**: Leverages GPU support for faster processing, enhancing performance significantly.\n",
      "\n",
      "5. **Open-Source and Community-Driven**: As an open-source tool, Docling benefits from community contributions and continuous improvement, aiming to bridge the gap between open-source and commercial PDF conversion tools.\n",
      "\n",
      "6. **Future Enhancements**: Ongoing development focuses on expanding model capabilities (e.g., better figure and equation extraction), enhancing GPU utilization, and thorough testing to ensure robustness and reliability.\n",
      "\n",
      "In summary, Docling stands out as a powerful, flexible, and community-supported tool designed to simplify and enhance PDF document conversion with state-of-the-art AI features.\n"
     ]
    }
   ],
   "source": [
    "# RAG 시스템 실행 예시\n",
    "result = run_rag_system(\"Docling에 대해 설명해줘.\")\n",
    "print(f\"최종 답변: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly! Here’s a concise explanation of Docling based on the provided information:\\n\\n**Docling** is an open-source PDF converter designed to address the complexities and variability inherent in PDF documents through advanced AI capabilities. Here are its key features and strengths:\\n\\n1. **Efficiency and Speed**: Docling quickly converts PDFs into structured formats like JSON or Markdown, making it highly efficient for both batch and interactive use cases.\\n\\n2. **Advanced Parsing**: It excels at understanding complex PDF structures, including:\\n   - **Page Layout**: Accurate interpretation of text placement and layout.\\n   - **Reading Order**: Proper sequencing of content for readability.\\n   - **Figures and Tables**: Extraction and preservation of visual elements and tabular data.\\n   - **Metadata**: Extraction of essential metadata such as titles, authors, and other document properties.\\n\\n3. **Versatility**: Docling supports OCR (Optical Character Recognition) for scanned PDFs, ensuring that even non-text content can be effectively processed.\\n\\n4. **Flexibility**: \\n   - **Extensibility**: Built with a modular pipeline architecture, allowing for customization and integration with various AI models.\\n   - **Mode Support**: Operates seamlessly in both batch processing and interactive modes, catering to diverse user needs.\\n   - **Acceleration**: Leverages GPU support for faster processing, enhancing performance significantly.\\n\\n5. **Open-Source and Community-Driven**: As an open-source tool, Docling benefits from community contributions and continuous improvement, aiming to bridge the gap between open-source and commercial PDF conversion tools.\\n\\n6. **Future Enhancements**: Ongoing development focuses on expanding model capabilities (e.g., better figure and equation extraction), enhancing GPU utilization, and thorough testing to ensure robustness and reliability.\\n\\nIn summary, Docling stands out as a powerful, flexible, and community-supported tool designed to simplify and enhance PDF document conversion with state-of-the-art AI features.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/backend/execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/subprocess.py:1837\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1836\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m dot\u001b[38;5;241m.\u001b[39medge(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEND\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# 그래프 렌더링\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mdot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrag_workflow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mview\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m display(dot)\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/_tools.py:185\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    178\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    179\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    182\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    183\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/_tools.py:185\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    178\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    179\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    180\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mqualification\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as keyword arg\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    182\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    183\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/backend/rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[0;32m~/anaconda3/envs/dacon/lib/python3.9/site-packages/graphviz/backend/execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "# 워크플로우 시각화\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "# workflow를 DOT 형식으로 변환\n",
    "dot = graphviz.Digraph(comment='RAG Workflow')\n",
    "dot.attr(rankdir='LR')  # 왼쪽에서 오른쪽으로 방향 설정\n",
    "\n",
    "# 노드 스타일 설정\n",
    "dot.attr('node', shape='box', style='rounded,filled', fillcolor='lightblue')\n",
    "\n",
    "# 노드 추가\n",
    "dot.node('START', 'START', shape='oval')\n",
    "dot.node('classify', 'Classify(질문 분류)')\n",
    "dot.node('retrieve', 'Retrieve(문서 검색)')\n",
    "dot.node('think', 'Think(추론)')\n",
    "dot.node('answer', 'Answer(답변 생성)')\n",
    "dot.node('END', 'END', shape='oval')\n",
    "\n",
    "# 엣지 추가\n",
    "dot.edge('START', 'classify')\n",
    "dot.edge('classify', 'retrieve', 'retrieve')\n",
    "dot.edge('classify', 'answer', 'generate')\n",
    "dot.edge('retrieve', 'think')\n",
    "dot.edge('think', 'answer')\n",
    "dot.edge('answer', 'END')\n",
    "\n",
    "# 그래프 렌더링\n",
    "dot.render('rag_workflow', format='png', view=True)\n",
    "display(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
